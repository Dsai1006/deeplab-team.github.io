---
layout: post
title: GANとStyleGAN(v2)
tags: [Seminars]
permalink: seminars/2020-05-10-gan
---

## 概要
敵対的生成ネットワーク(GAN)は深層生成モデルの一つであり，適切に学習すれば，学習訓練データ集合に無く，かつ訓練データと見分けがつかないよいうなデータを生成することができます．本セミナーでは，近年世界に衝撃を与えたGANであるStyleGANを中心にして，GANの構造を説明します．さらに発展的な話題として，現実画像を潜在変数空間に落とし込む手法も説明します．

## 目的
- GANの基本構造の理解する．
- StyleGANおよびStyleGANv2の構造を理解する．
- 現実世界の画像を潜在空間に落とし込む手法を理解する．

## 発表日時
場所:  オンライン (Zoom) \
日時: 2020年5月10日 10時 - 12時

## 参考資料
I. Goodfellow et al. Generative Adversarial Networks. NeurIPS, 2017. [[arXiv]](https://arxiv.org/abs/1406.2661) 

A. Radford et al. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. ICLR, 2016. [[arXiv]](https://arxiv.org/abs/1511.06434) 

M. Arjovsky et al. Wasserstein GAN. ICML, 2017. [[arXiv]](https://arxiv.org/abs/1701.07875) 

T. Karras et al. A Style-Based Generator Architecture for Generative Adversarial Networks. CVPR, 2019. [[arXiv]](https://arxiv.org/abs/1812.04948) 

X. Huang et al. Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization. ICCV, 2017. [[arXiv]](https://arxiv.org/abs/1703.06868) 

T. Karras et al. Analyzing and Improving the Image Quality of StyleGAN. CVPR, 2020. [[arXiv]](https://arxiv.org/abs/1912.04958) 

R. Abdal et al. Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?. CVPR, 2019. [[arXiv]](https://arxiv.org/abs/1904.03189) 

R. Abdal et al. Image2StyleGAN++: How to Edit the Embedded Images?. CVPR, 2020. [[arXiv]](https://arxiv.org/abs/1911.11544)